{"cells":[{"cell_type":"code","source":["import os\n","from pathlib import Path\n","import random\n","from datetime import datetime, timedelta\n","import uuid\n","import pandas as pd\n","import json\n","import sys\n","\n","client = \"800\"\n","\n","DELETE_PROBABILITY = 0.05\n","UPDATE_PROBABILITY = 0.60\n","INSERT_PROBABILITY = 0.35\n","\n","last_sequence_id = 0\n","\n","\n","class TableConfig:\n","    def __init__(self, name, key_fields, weight=10, field_generators=None, related_tables=None):\n","        self.name = name\n","        self.key_fields = key_fields\n","        self.weight = weight\n","        self.field_generators = field_generators or {}\n","        self.related_tables = related_tables or []\n","\n","\n","class CDCGenerator:\n","    def __init__(self, base_seed_path=\"/lakehouse/default/Files/inbound-sap-seed\",\n","                 base_cdc_path=\"/lakehouse/default/Files/inbound-sap-cdc\"):\n","        self.base_seed_path = base_seed_path\n","        self.base_cdc_path = base_cdc_path\n","        self.table_configs = {}\n","        self.data_cache = {}\n","        self._init_sequence_id()\n","\n","    def _init_sequence_id(self):\n","        global last_sequence_id\n","        last_sequence_id = int(datetime.now().timestamp() * 1000)\n","\n","    def get_next_sequence_id(self):\n","        global last_sequence_id\n","        last_sequence_id += 1\n","        return last_sequence_id\n","\n","    def register_table(self, table_config):\n","        self.table_configs[table_config.name] = table_config\n","        return self\n","\n","    def get_parquet_files(self, table_name):\n","        table_path = f\"{self.base_seed_path}/{table_name}\"\n","\n","        if not os.path.exists(table_path):\n","            print(f\"Path not found: {table_path}\")\n","            return []\n","\n","        parquet_files = []\n","\n","        for root, dirs, files in os.walk(table_path):\n","            for file in files:\n","                if file.endswith('.parquet'):\n","                    parquet_files.append(os.path.join(root, file))\n","\n","        return parquet_files\n","\n","    def read_latest_data(self, table_name):\n","        if table_name in self.data_cache:\n","            return self.data_cache[table_name]\n","\n","        parquet_files = self.get_parquet_files(table_name)\n","\n","        if not parquet_files:\n","            print(f\"No parquet files found for {table_name}\")\n","            return pd.DataFrame()\n","\n","        def sort_key(file_path):\n","            parts = file_path.split('/')\n","            date_parts = []\n","            for part in parts:\n","                if part.isdigit() and (len(part) == 4 or len(part) == 2):\n","                    date_parts.append(part)\n","            \n","            if len(date_parts) >= 3:\n","                date_str = ''.join(date_parts[:3])\n","                return date_str + str(os.path.getctime(file_path))\n","            else:\n","                return str(os.path.getctime(file_path))\n","        \n","        latest_file = sorted(parquet_files, key=sort_key, reverse=True)[0]\n","        print(f\"Reading latest data from: {latest_file}\")\n","\n","        df = pd.read_parquet(latest_file)\n","        self.data_cache[table_name] = df\n","        return df\n","\n","    def write_cdc_data(self, df, table_name):\n","        if df.empty:\n","            print(f\"No CDC data to write for {table_name}\")\n","            return None\n","\n","        current_time = datetime.now()\n","        year = current_time.strftime(\"%Y\")\n","        month = current_time.strftime(\"%m\")\n","        day = current_time.strftime(\"%d\")\n","        timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n","\n","        output_path = f\"{self.base_cdc_path}/{table_name}\"\n","        Path(output_path).mkdir(parents=True, exist_ok=True)\n","\n","        table_config = self.table_configs.get(table_name)\n","        metadata = {\n","            \"table_name\": table_name,\n","            \"key_fields\": table_config.key_fields if table_config else [],\n","            \"cdc_timestamp\": timestamp,\n","            \"record_count\": len(df),\n","            \"insert_count\": len(df[df[\"action_type\"] == \"I\"]),\n","            \"update_count\": len(df[df[\"action_type\"] == \"U\"]),\n","            \"delete_count\": len(df[df[\"action_type\"] == \"D\"])\n","        }\n","\n","        metadata_file = f\"{output_path}/{table_name}_CDC_{timestamp}_metadata.json\"\n","        with open(metadata_file, 'w') as f:\n","            json.dump(metadata, f, indent=2)\n","\n","        output_file = f\"{output_path}/{table_name}_CDC_{timestamp}.csv\"\n","        df.to_parquet(output_file)\n","\n","        print(f\"Writing CDC data for {table_name} to {output_path}\")\n","        return output_path\n","\n","    def generate_changes(self, table_name, num_changes):\n","        if table_name not in self.table_configs:\n","            print(f\"No configuration found for table {table_name}\")\n","            return pd.DataFrame()\n","\n","        table_config = self.table_configs[table_name]\n","        df = self.read_latest_data(table_name)\n","\n","        if df.empty:\n","            print(f\"No existing data for {table_name}\")\n","            return pd.DataFrame()\n","\n","        key_fields = table_config.key_fields\n","        existing_records = df[key_fields].drop_duplicates().values.tolist()\n","\n","        changes = []\n","\n","        for _ in range(num_changes):\n","            action_type = random.choices(\n","                [\"I\", \"U\", \"D\"],\n","                weights=[INSERT_PROBABILITY, UPDATE_PROBABILITY, DELETE_PROBABILITY]\n","            )[0]\n","\n","            if action_type == \"I\":\n","                new_record = self._generate_insert(table_name, df, existing_records)\n","                if new_record:\n","                    changes.append(new_record)\n","\n","            elif action_type == \"U\":\n","                updated_record = self._generate_update(table_name, df, existing_records)\n","                if updated_record:\n","                    changes.append(updated_record)\n","\n","            elif action_type == \"D\":\n","                deleted_record = self._generate_delete(table_name, df, existing_records)\n","                if deleted_record:\n","                    key_values = [deleted_record[key] for key in key_fields]\n","                    try:\n","                        existing_records.remove(key_values)\n","                    except ValueError:\n","                        pass\n","                    changes.append(deleted_record)\n","\n","        return pd.DataFrame(changes)\n","\n","    def _generate_insert(self, table_name, df, existing_records):\n","        table_config = self.table_configs[table_name]\n","\n","        new_record = {\"mandt\": client}\n","\n","        for field, generator in table_config.field_generators.items():\n","            if callable(generator):\n","                new_record[field] = generator(self, table_name, df)\n","            elif isinstance(generator, dict) and \"related_table\" in generator:\n","                related_table = generator[\"related_table\"]\n","                related_df = self.read_latest_data(related_table)\n","                if not related_df.empty:\n","                    field_values = related_df[generator[\"field\"]].unique().tolist()\n","                    if field_values:\n","                        new_record[field] = random.choice(field_values)\n","\n","        new_record[\"action_type\"] = \"I\"\n","        new_record[\"row_insert_timestamp\"] = datetime.now()\n","        new_record[\"row_update_timestamp\"] = datetime.now()\n","        new_record[\"sequence_id\"] = self.get_next_sequence_id()\n","\n","        return new_record\n","\n","    def _generate_update(self, table_name, df, existing_records):\n","        if not existing_records:\n","            return None\n","\n","        table_config = self.table_configs[table_name]\n","        key_fields = table_config.key_fields\n","\n","        random_key = random.choice(existing_records)\n","\n","        filter_condition = True\n","        for i, key_field in enumerate(key_fields):\n","            filter_condition = filter_condition & (df[key_field] == random_key[i])\n","\n","        try:\n","            original_row = df[filter_condition].iloc[0].to_dict()\n","        except (IndexError, KeyError):\n","            return None\n","\n","        for field, generator in table_config.field_generators.items():\n","            if field in key_fields:\n","                continue\n","\n","            if callable(generator):\n","                original_row[field] = generator(self, table_name, df, original_row)\n","            elif isinstance(generator, dict) and \"updatable\" in generator and generator[\"updatable\"]:\n","                if \"values\" in generator:\n","                    original_row[field] = random.choice(generator[\"values\"])\n","                elif \"range\" in generator:\n","                    min_val, max_val = generator[\"range\"]\n","                    original_row[field] = random.uniform(min_val, max_val)\n","\n","        original_row[\"action_type\"] = \"U\"\n","        original_row[\"row_update_timestamp\"] = datetime.now()\n","        original_row[\"sequence_id\"] = self.get_next_sequence_id()\n","\n","        return original_row\n","\n","    def _generate_delete(self, table_name, df, existing_records):\n","        if not existing_records:\n","            return None\n","\n","        table_config = self.table_configs[table_name]\n","        key_fields = table_config.key_fields\n","\n","        random_key = random.choice(existing_records)\n","\n","        filter_condition = True\n","        for i, key_field in enumerate(key_fields):\n","            filter_condition = filter_condition & (df[key_field] == random_key[i])\n","\n","        try:\n","            original_row = df[filter_condition].iloc[0].to_dict()\n","        except (IndexError, KeyError):\n","            return None\n","\n","        original_row[\"action_type\"] = \"D\"\n","        original_row[\"row_update_timestamp\"] = datetime.now()\n","        original_row[\"sequence_id\"] = self.get_next_sequence_id()\n","\n","        return original_row\n","\n","    def generate_transaction_group_changes(self, header_table, item_tables, num_transactions):\n","        header_df = self.read_latest_data(header_table)\n","        if header_df.empty:\n","            print(f\"No header data for {header_table}\")\n","            return {}\n","\n","        header_config = self.table_configs[header_table]\n","        id_field = header_config.key_fields[1]\n","\n","        all_changes = {header_table: []}\n","        for item_table in item_tables:\n","            all_changes[item_table] = []\n","\n","        for _ in range(num_transactions):\n","            action_type = random.choices(\n","                [\"I\", \"U\", \"D\"],\n","                weights=[INSERT_PROBABILITY, UPDATE_PROBABILITY, DELETE_PROBABILITY]\n","            )[0]\n","\n","            sequence_id = self.get_next_sequence_id()\n","\n","            if action_type == \"I\":\n","                pass\n","            elif action_type == \"U\":\n","                if header_df.empty:\n","                    continue\n","\n","                random_header = header_df.sample(1).iloc[0]\n","                doc_id = random_header[id_field]\n","\n","                header_change = random_header.to_dict()\n","                header_change[\"action_type\"] = \"U\"\n","                header_change[\"row_update_timestamp\"] = datetime.now()\n","                header_change[\"sequence_id\"] = sequence_id\n","                all_changes[header_table].append(header_change)\n","\n","                for item_table in item_tables:\n","                    item_df = self.read_latest_data(item_table)\n","                    if item_df.empty:\n","                        continue\n","\n","                    items = item_df[item_df[id_field] == doc_id]\n","                    for _, item in items.iterrows():\n","                        item_change = item.to_dict()\n","                        item_change[\"action_type\"] = \"U\"\n","                        item_change[\"row_update_timestamp\"] = datetime.now()\n","                        item_change[\"sequence_id\"] = sequence_id\n","                        all_changes[item_table].append(item_change)\n","\n","            elif action_type == \"D\":\n","                if header_df.empty:\n","                    continue\n","\n","                random_header = header_df.sample(1).iloc[0]\n","                doc_id = random_header[id_field]\n","\n","                header_change = random_header.to_dict()\n","                header_change[\"action_type\"] = \"D\"\n","                header_change[\"row_update_timestamp\"] = datetime.now()\n","                header_change[\"sequence_id\"] = sequence_id\n","                all_changes[header_table].append(header_change)\n","\n","                for item_table in item_tables:\n","                    item_df = self.read_latest_data(item_table)\n","                    if item_df.empty:\n","                        continue\n","\n","                    items = item_df[item_df[id_field] == doc_id]\n","                    for _, item in items.iterrows():\n","                        item_change = item.to_dict()\n","                        item_change[\"action_type\"] = \"D\"\n","                        item_change[\"row_update_timestamp\"] = datetime.now()\n","                        item_change[\"sequence_id\"] = sequence_id\n","                        all_changes[item_table].append(item_change)\n","\n","        results = {}\n","        for table, changes in all_changes.items():\n","            if changes:\n","                results[table] = pd.DataFrame(changes)\n","            else:\n","                results[table] = pd.DataFrame()\n","\n","        return results\n","\n","    def run_simulation(self, changes_per_table=25):\n","        print(f\"Starting CDC simulation with {changes_per_table} changes per table...\")\n","\n","        self._init_sequence_id()\n","        total_weight = sum(config.weight for config in self.table_configs.values())\n","\n","        table_changes = {}\n","        for table_name, config in self.table_configs.items():\n","            weight = config.weight\n","            changes_for_table = max(1, int((weight / total_weight) * changes_per_table * 10))\n","            table_changes[table_name] = changes_for_table\n","\n","        results = {}\n","\n","        processed_tables = set()\n","\n","        for table_name, config in self.table_configs.items():\n","            if table_name in processed_tables or not config.related_tables:\n","                continue\n","\n","            item_tables = config.related_tables\n","\n","            print(f\"Generating transaction group changes for {table_name} and related tables...\")\n","            group_changes = self.generate_transaction_group_changes(\n","                table_name, item_tables, table_changes[table_name]\n","            )\n","\n","            for group_table, changes_df in group_changes.items():\n","                if not changes_df.empty:\n","                    self.write_cdc_data(changes_df, group_table)\n","                    results[group_table] = len(changes_df)\n","\n","            processed_tables.add(table_name)\n","            processed_tables.update(item_tables)\n","\n","        for table_name, config in self.table_configs.items():\n","            if table_name in processed_tables:\n","                continue\n","\n","            print(f\"Generating changes for {table_name}...\")\n","            changes_df = self.generate_changes(table_name, table_changes[table_name])\n","\n","            if not changes_df.empty:\n","                self.write_cdc_data(changes_df, table_name)\n","                results[table_name] = len(changes_df)\n","\n","        total_changes = sum(results.values())\n","        results[\"total\"] = total_changes\n","\n","        print(f\"CDC simulation complete. Generated {total_changes} total changes across all tables.\")\n","        return results\n","\n","\n","def generate_material_number(generator, table_name, df, existing_record=None):\n","    if existing_record is not None:\n","        return existing_record[\"matnr\"]\n","    return f\"MAT{random.randint(10000, 99999):05d}\"\n","\n","\n","def generate_customer_number(generator, table_name, df, existing_record=None):\n","    if existing_record is not None:\n","        return existing_record[\"kunnr\"]\n","    return f\"CUST{random.randint(1000, 9999):04d}\"\n","\n","\n","def generate_vendor_number(generator, table_name, df, existing_record=None):\n","    if existing_record is not None:\n","        return existing_record[\"lifnr\"]\n","    return f\"VEND{random.randint(1000, 9999):04d}\"\n","\n","\n","def generate_random_quantity(generator, table_name, df, existing_record=None):\n","    if existing_record is not None:\n","        old_quantity = existing_record[\"menge\"]\n","        new_quantity = int(old_quantity * random.uniform(0.8, 1.2))\n","        return max(1, new_quantity)\n","    return random.randint(1, 100)\n","\n","\n","def configure_sap_cdc_generator():\n","    generator = CDCGenerator()\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_mara\",\n","        key_fields=[\"mandt\", \"matnr\"],\n","        weight=10,\n","        field_generators={\n","            \"matnr\": generate_material_number,\n","            \"mtart\": {\"values\": [\"ROH\", \"HALB\", \"FERT\", \"HAWA\"], \"updatable\": True},\n","            \"mbrsh\": {\"values\": [\"M\", \"W\"], \"updatable\": False},\n","            \"matkl\": {\"values\": [\"0100\", \"0200\", \"0300\", \"0400\", \"0500\"], \"updatable\": True},\n","            \"meins\": {\"values\": [\"EA\", \"PC\", \"KG\", \"L\", \"M\"], \"updatable\": False},\n","            \"bstme\": {\"values\": [\"EA\", \"PC\", \"KG\", \"L\", \"M\"], \"updatable\": True},\n","            \"volum\": {\"range\": [0.1, 100], \"updatable\": True},\n","            \"ntgew\": {\"range\": [0.5, 45], \"updatable\": True}\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_marc\",\n","        key_fields=[\"mandt\", \"matnr\", \"werks\"],\n","        weight=15,\n","        field_generators={\n","            \"matnr\": {\"related_table\": \"sap_mara\", \"field\": \"matnr\"},\n","            \"werks\": {\"values\": [\"1000\", \"2000\", \"3000\", \"4000\"], \"updatable\": False},\n","            \"lgpro\": {\"values\": [\"0001\", \"0002\", \"0003\", \"0004\"], \"updatable\": True},\n","            \"lgfsb\": {\"values\": [\"0001\", \"0002\", \"0003\", \"0004\"], \"updatable\": True},\n","            \"dismm\": {\"values\": [\"VB\", \"ND\", \"VM\"], \"updatable\": True},\n","            \"minbe\": {\"range\": [0, 100], \"updatable\": True},\n","            \"eisbe\": {\"range\": [100, 500], \"updatable\": True}\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_kna1\",\n","        key_fields=[\"mandt\", \"kunnr\"],\n","        weight=8,\n","        field_generators={\n","            \"kunnr\": generate_customer_number,\n","            \"land1\": {\"values\": [\"US\", \"DE\", \"FR\", \"GB\", \"IT\", \"ES\", \"JP\", \"CN\"], \"updatable\": True},\n","            \"name1\": lambda g, t, df, r=None: f\"Customer {r['kunnr'] if r else generate_customer_number(g, t, df)}\",\n","            \"telf1\": lambda g, t, df,\n","                            r=None: f\"{random.randint(100, 999)}-{random.randint(100, 999)}-{random.randint(1000, 9999)}\",\n","            \"kukla\": {\"values\": [\"01\", \"02\", \"03\"], \"updatable\": True}\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_lfa1\",\n","        key_fields=[\"mandt\", \"lifnr\"],\n","        weight=5,\n","        field_generators={\n","            \"lifnr\": generate_vendor_number,\n","            \"land1\": {\"values\": [\"US\", \"DE\", \"FR\", \"GB\", \"IT\", \"ES\", \"JP\", \"CN\"], \"updatable\": True},\n","            \"name1\": lambda g, t, df, r=None: f\"Vendor {r['lifnr'] if r else generate_vendor_number(g, t, df)}\",\n","            \"telf1\": lambda g, t, df,\n","                            r=None: f\"{random.randint(100, 999)}-{random.randint(100, 999)}-{random.randint(1000, 9999)}\"\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_vbak\",\n","        key_fields=[\"mandt\", \"vbeln\"],\n","        weight=12,\n","        related_tables=[\"sap_vbap\"],\n","        field_generators={\n","            \"vbeln\": lambda g, t, df, r=None: r[\"vbeln\"] if r else f\"OR{random.randint(100000, 999999):06d}\",\n","            \"auart\": {\"values\": [\"OR\", \"TA\", \"ZOR\"], \"updatable\": True},\n","            \"vkorg\": {\"values\": [\"1000\", \"2000\"], \"updatable\": False},\n","            \"vtweg\": {\"values\": [\"10\", \"20\"], \"updatable\": False},\n","            \"spart\": {\"values\": [\"00\", \"01\"], \"updatable\": False},\n","            \"netwr\": {\"range\": [100, 10000], \"updatable\": True},\n","            \"waerk\": {\"values\": [\"USD\", \"EUR\", \"GBP\"], \"updatable\": False},\n","            \"kunnr\": {\"related_table\": \"sap_kna1\", \"field\": \"kunnr\"}\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_vbap\",\n","        key_fields=[\"mandt\", \"vbeln\", \"posnr\"],\n","        weight=20,\n","        field_generators={\n","            \"vbeln\": {\"related_table\": \"sap_vbak\", \"field\": \"vbeln\"},\n","            \"posnr\": lambda g, t, df, r=None: r[\"posnr\"] if r else f\"{random.randint(1, 99):06d}\",\n","            \"matnr\": {\"related_table\": \"sap_mara\", \"field\": \"matnr\"},\n","            \"werks\": {\"values\": [\"1000\", \"2000\", \"3000\", \"4000\"], \"updatable\": True},\n","            \"menge\": generate_random_quantity,\n","            \"netwr\": lambda g, t, df, r=None: r[\"netwr\"] if r else random.uniform(10, 1000) * (\n","                r[\"menge\"] if r else random.randint(1, 100))\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_ekko\",\n","        key_fields=[\"mandt\", \"ebeln\"],\n","        weight=10,\n","        related_tables=[\"sap_ekpo\"],\n","        field_generators={\n","            \"ebeln\": lambda g, t, df, r=None: r[\"ebeln\"] if r else f\"PO{random.randint(100000, 999999):06d}\",\n","            \"bukrs\": {\"values\": [\"1000\", \"2000\", \"3000\"], \"updatable\": False},\n","            \"bstyp\": {\"values\": [\"F\", \"L\", \"K\"], \"updatable\": False},\n","            \"lifnr\": {\"related_table\": \"sap_lfa1\", \"field\": \"lifnr\"},\n","            \"ekorg\": {\"values\": [\"1000\", \"2000\"], \"updatable\": False},\n","            \"waers\": {\"values\": [\"USD\", \"EUR\", \"GBP\"], \"updatable\": False}\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_ekpo\",\n","        key_fields=[\"mandt\", \"ebeln\", \"ebelp\"],\n","        weight=15,\n","        field_generators={\n","            \"ebeln\": {\"related_table\": \"sap_ekko\", \"field\": \"ebeln\"},\n","            \"ebelp\": lambda g, t, df, r=None: r[\"ebelp\"] if r else f\"{random.randint(1, 99):05d}\",\n","            \"matnr\": {\"related_table\": \"sap_mara\", \"field\": \"matnr\"},\n","            \"werks\": {\"values\": [\"1000\", \"2000\", \"3000\", \"4000\"], \"updatable\": True},\n","            \"lgort\": {\"values\": [\"0001\", \"0002\", \"0003\", \"0004\"], \"updatable\": True},\n","            \"menge\": generate_random_quantity,\n","            \"netpr\": {\"range\": [10, 1000], \"updatable\": True}\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_bkpf\",\n","        key_fields=[\"mandt\", \"bukrs\", \"belnr\", \"gjahr\"],\n","        weight=10,\n","        related_tables=[\"sap_bseg\"],\n","        field_generators={\n","            \"bukrs\": {\"values\": [\"1000\", \"2000\", \"3000\"], \"updatable\": False},\n","            \"belnr\": lambda g, t, df, r=None: r[\"belnr\"] if r else f\"AC{random.randint(100000, 999999):06d}\",\n","            \"gjahr\": lambda g, t, df, r=None: r[\"gjahr\"] if r else str(random.randint(2023, 2024)),\n","            \"blart\": {\"values\": [\"SA\", \"KR\", \"DR\"], \"updatable\": True},\n","            \"waers\": {\"values\": [\"USD\", \"EUR\", \"GBP\"], \"updatable\": False},\n","            \"bktxt\": lambda g, t, df, r=None: f\"Accounting Doc {r['belnr'] if r else 'New'}\"\n","        }\n","    ))\n","\n","    generator.register_table(TableConfig(\n","        name=\"sap_bseg\",\n","        key_fields=[\"mandt\", \"bukrs\", \"belnr\", \"gjahr\", \"buzei\"],\n","        weight=15,\n","        field_generators={\n","            \"bukrs\": {\"related_table\": \"sap_bkpf\", \"field\": \"bukrs\"},\n","            \"belnr\": {\"related_table\": \"sap_bkpf\", \"field\": \"belnr\"},\n","            \"gjahr\": {\"related_table\": \"sap_bkpf\", \"field\": \"gjahr\"},\n","            \"buzei\": lambda g, t, df, r=None: r[\"buzei\"] if r else f\"{random.randint(1, 99):03d}\",\n","            \"koart\": {\"values\": [\"S\", \"K\", \"D\"], \"updatable\": False},\n","            \"shkzg\": {\"values\": [\"S\", \"H\"], \"updatable\": True},\n","            \"wrbtr\": {\"range\": [100, 5000], \"updatable\": True},\n","            \"dmbtr\": lambda g, t, df, r=None: r[\"wrbtr\"] if r and \"wrbtr\" in r else random.uniform(100, 5000)\n","        }\n","    ))\n","\n","    return generator\n","\n","\n","if __name__ == \"__main__\" or 'ipykernel' in sys.modules:\n","    if 'ipykernel' in sys.modules:\n","        changes_per_table = 25\n","        \n","        cdc_generator = configure_sap_cdc_generator()\n","        results = cdc_generator.run_simulation(changes_per_table=changes_per_table)\n","    else:\n","        import argparse\n","\n","        parser = argparse.ArgumentParser(description='Generate SAP CDC simulation data')\n","        parser.add_argument('--changes', type=int, default=25,\n","                            help='Number of changes per table (weighted by table importance)')\n","\n","        args = parser.parse_args()\n","\n","        cdc_generator = configure_sap_cdc_generator()\n","        results = cdc_generator.run_simulation(changes_per_table=args.changes)\n","\n","    print(\"\\nChange summary:\")\n","    for table, count in results.items():\n","        if table != \"total\":\n","            print(f\"  - {table}: {count} changes\")\n","    print(f\"Total changes: {results['total']}\")\n","\n","\n","    "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"4ba59e54-e416-410e-8d77-92d7228ab886","normalized_state":"finished","queued_time":"2025-03-26T20:32:15.4883605Z","session_start_time":null,"execution_start_time":"2025-03-26T20:32:20.3618477Z","execution_finish_time":"2025-03-26T20:32:27.4096327Z","parent_msg_id":"4ce62a81-9591-4eb2-a8a0-d49883241106"},"text/plain":"StatementMeta(, 4ba59e54-e416-410e-8d77-92d7228ab886, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Starting CDC simulation with 25 changes per table...\nGenerating transaction group changes for sap_vbak and related tables...\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_vbak/sap_vbak_20250320_052654.parquet\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_vbap/sap_vbap_20250320_052654.parquet\nWriting CDC data for sap_vbak to /lakehouse/default/Files/inbound-sap-cdc/sap_vbak\nWriting CDC data for sap_vbap to /lakehouse/default/Files/inbound-sap-cdc/sap_vbap\nGenerating transaction group changes for sap_ekko and related tables...\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_ekko/sap_ekko_20250320_052654.parquet\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_ekpo/sap_ekpo_20250320_052654.parquet\nWriting CDC data for sap_ekko to /lakehouse/default/Files/inbound-sap-cdc/sap_ekko\nWriting CDC data for sap_ekpo to /lakehouse/default/Files/inbound-sap-cdc/sap_ekpo\nGenerating transaction group changes for sap_bkpf and related tables...\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_bkpf/sap_bkpf_20250320_052655.parquet\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_bseg/sap_bseg_20250320_052655.parquet\nWriting CDC data for sap_bkpf to /lakehouse/default/Files/inbound-sap-cdc/sap_bkpf\nWriting CDC data for sap_bseg to /lakehouse/default/Files/inbound-sap-cdc/sap_bseg\nGenerating changes for sap_mara...\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_mara/sap_mara_20250320_052653.parquet\nWriting CDC data for sap_mara to /lakehouse/default/Files/inbound-sap-cdc/sap_mara\nGenerating changes for sap_marc...\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_marc/sap_marc_20250320_052654.parquet\nWriting CDC data for sap_marc to /lakehouse/default/Files/inbound-sap-cdc/sap_marc\nGenerating changes for sap_kna1...\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_kna1/sap_kna1_20250320_052654.parquet\nWriting CDC data for sap_kna1 to /lakehouse/default/Files/inbound-sap-cdc/sap_kna1\nGenerating changes for sap_lfa1...\nReading latest data from: /lakehouse/default/Files/inbound-sap-seed/sap_lfa1/sap_lfa1_20250320_052654.parquet\nWriting CDC data for sap_lfa1 to /lakehouse/default/Files/inbound-sap-cdc/sap_lfa1\nCDC simulation complete. Generated 560 total changes across all tables.\n\nChange summary:\n  - sap_vbak: 19 changes\n  - sap_vbap: 62 changes\n  - sap_ekko: 11 changes\n  - sap_ekpo: 32 changes\n  - sap_bkpf: 12 changes\n  - sap_bseg: 347 changes\n  - sap_mara: 20 changes\n  - sap_marc: 31 changes\n  - sap_kna1: 16 changes\n  - sap_lfa1: 10 changes\nTotal changes: 560\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"003b7f78-7232-4360-af89-04661d1eb6a6"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"4b474d5b-a00f-4b15-b460-2544da2b26f9","default_lakehouse_name":"sap_inbound_cdc_data_lh","default_lakehouse_workspace_id":"8616b403-135f-4b8c-a3cd-7c9388000584"}}},"nbformat":4,"nbformat_minor":5}